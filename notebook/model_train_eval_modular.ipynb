{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 300\n",
    "%reload_ext autoreload\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\n",
    "    r\"/home/azureuser/cloudfiles/code/Users/soutrik.chowdhury/abi_genai_bert_classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.model_helpers import (\n",
    "    set_seed,\n",
    "    plot_loss_accuracy,\n",
    "    get_device,\n",
    ")\n",
    "from src.preprocess import data_preprocess\n",
    "from src.settings import (\n",
    "    DataSettings,\n",
    "    env_settings,\n",
    "    ModelSettings,\n",
    "    TokenizerSettings,\n",
    "    AzureblobSettings,\n",
    "    LoggerSettings\n",
    ")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.pretrained_model import tokenizer, pretrained_model\n",
    "from src.dataloader import create_data_loader\n",
    "from src.model import BertSentimentClassifier, BertSentimentClassifierAdvanced\n",
    "from src.trainer import train_module, test_module, training_drivers, get_predictions\n",
    "import json\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from src.utils.azure_connector import AzureBlobConnection\n",
    "from src.utils.logger import setup_logging # type: ignore\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\n",
    "    \"#01BEFE\",\n",
    "    \"#FFDD00\",\n",
    "    \"#FF7D00\",\n",
    "    \"#FF006D\",\n",
    "    \"#ADFF02\",\n",
    "    \"#8F00FF\",\n",
    "]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = setup_logging(\n",
    "            logger_name=LoggerSettings().logger_name,\n",
    "            log_file='ModelTrainEval.log',\n",
    "            log_level=LoggerSettings().log_level,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Consolidating all the syntesized files\")\n",
    "folder_path = os.path.join(os.getcwd(), DataSettings().data_path)\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith(\".csv\")]\n",
    "concatenated_df = pd.concat(\n",
    "    (pd.read_csv(os.path.join(folder_path, file)) for file in csv_files),\n",
    "    ignore_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of the labels\n",
    "plt.figure(figsize=(13, 7))\n",
    "sns.countplot(data=concatenated_df, x='Domain', hue='FinalLabel')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Domain Distribution')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data_preprocess(\n",
    "    concatenated_df, DataSettings().evaluation_size, ModelSettings().seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test dataloader\n",
    "logger.info(\"Creating train and test dataloaders\")\n",
    "train_loader = create_data_loader(\n",
    "    question=train_df[\"Question\"].values,\n",
    "    targets=train_df[\"FinalLabel\"].values,\n",
    "    max_len=TokenizerSettings().max_length,\n",
    "    batch_size=TokenizerSettings().batch_size,\n",
    "    shuffle=True,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "test_loader = create_data_loader(\n",
    "    question=test_df[\"Question\"].values,\n",
    "    targets=test_df[\"FinalLabel\"].values,\n",
    "    max_len=TokenizerSettings().max_length,\n",
    "    batch_size=TokenizerSettings().batch_size,\n",
    "    shuffle=False,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batched of 8 with 128 token size\n",
    "for train_data in train_loader:\n",
    "    logger.info(train_data.keys())\n",
    "    logger.info(f\"Shape of the val input ids: {train_data['input_ids'].shape}\")\n",
    "    logger.info(f\"Shape of val attention heads: {train_data['attention_mask'].shape}\")\n",
    "    logger.info(f\"Shape of val targets:: {train_data['targets'].shape}\")\n",
    "    logger.info(\"\\n\")\n",
    "    break\n",
    "\n",
    "for test_data in test_loader:\n",
    "    logger.info(test_data.keys())\n",
    "    logger.info(f\"Shape of the val input ids: {test_data['input_ids'].shape}\")\n",
    "    logger.info(f\"Shape of val attention heads: {test_data['attention_mask'].shape}\")\n",
    "    logger.info(f\"Shape of val targets:: {test_data['targets'].shape}\")\n",
    "    logger.info(\"\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(ModelSettings().seed)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Base Classifier\")\n",
    "bert_base_classifier = BertSentimentClassifier(\n",
    "    pretrained_model, ModelSettings().num_classes,ModelSettings().drop_out\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, optimizer, scheduler, metric, early_stopping = training_drivers(\n",
    "    bert_base_classifier,\n",
    "    learning_rate=ModelSettings().learning_rate,\n",
    "    train_loader=train_loader,\n",
    "    epochs=ModelSettings().epochs,\n",
    "    device=device,\n",
    "    model_name=\"base_bert_model.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_metrics = []\n",
    "test_losses = []\n",
    "test_metrics = []\n",
    "\n",
    "for epoch in range(ModelSettings().epochs):\n",
    "\n",
    "    logger.info(f\"Epoch {epoch + 1}/{ModelSettings().epochs}\")\n",
    "    logger.info(\"-\" * 10)\n",
    "\n",
    "    train_losses, train_metrics = train_module(\n",
    "        model=bert_base_classifier,\n",
    "        device=device,\n",
    "        train_dataloader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        metric=metric,\n",
    "        scheduler=scheduler,\n",
    "        train_losses=train_losses,\n",
    "        train_metrics=train_metrics,\n",
    "    )\n",
    "\n",
    "    test_losses, test_metrics = test_module(\n",
    "        model=bert_base_classifier,\n",
    "        device=device,\n",
    "        test_dataloader=test_loader,\n",
    "        criterion=criterion,\n",
    "        metric=metric,\n",
    "        test_losses=test_losses,\n",
    "        test_metrics=test_metrics,\n",
    "    )\n",
    "    scheduler.step()\n",
    "\n",
    "    logger.info(f\"The learing rate is going to be next::{scheduler.get_last_lr()}\")\n",
    "\n",
    "    early_stopping(\n",
    "        test_losses[-1], bert_base_classifier, epoch\n",
    "    )  # last recorded test loss to measure the improvement against the prior one\n",
    "    if early_stopping.early_stop:\n",
    "        logger.info(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(train_loss= [train_losses],\n",
    "                   val_loss= [test_losses],\n",
    "                   train_acc= [train_metrics],\n",
    "                   val_acc= [test_metrics],\n",
    "                   labels=['baseline_Bert'],\n",
    "                   colors=['blue'],\n",
    "                   loss_legend_loc='upper left',\n",
    "                   acc_legend_loc='upper left',\n",
    "                   legend_font=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Advanced Classifier\")\n",
    "bert_advanced_classifier = BertSentimentClassifierAdvanced(\n",
    "    bert=pretrained_model,\n",
    "    n_classes=ModelSettings().num_classes,\n",
    "    dropout=ModelSettings().drop_out,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, optimizer, scheduler, metric, early_stopping = training_drivers(\n",
    "    bert_advanced_classifier,\n",
    "    learning_rate=ModelSettings().learning_rate,\n",
    "    train_loader=train_loader,\n",
    "    epochs=ModelSettings().epochs,\n",
    "    device=device,\n",
    "    model_name=\"advanced_bert_model.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_metrics = []\n",
    "test_losses = []\n",
    "test_metrics = []\n",
    "\n",
    "for epoch in range(ModelSettings().epochs):\n",
    "\n",
    "    logger.info(f\"Epoch {epoch + 1}/{ModelSettings().epochs}\")\n",
    "    logger.info(\"-\" * 10)\n",
    "\n",
    "    train_losses, train_metrics = train_module(\n",
    "        model=bert_advanced_classifier,\n",
    "        device=device,\n",
    "        train_dataloader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        metric=metric,\n",
    "        scheduler=scheduler,\n",
    "        train_losses=train_losses,\n",
    "        train_metrics=train_metrics,\n",
    "    )\n",
    "\n",
    "    test_losses, test_metrics = test_module(\n",
    "        model=bert_advanced_classifier,\n",
    "        device=device,\n",
    "        test_dataloader=test_loader,\n",
    "        criterion=criterion,\n",
    "        metric=metric,\n",
    "        test_losses=test_losses,\n",
    "        test_metrics=test_metrics,\n",
    "    )\n",
    "    scheduler.step()\n",
    "\n",
    "    logger.info(f\"The learing rate is going to be next::{scheduler.get_last_lr()}\")\n",
    "\n",
    "    early_stopping(\n",
    "        test_losses[-1], bert_advanced_classifier, epoch\n",
    "    )  # last recorded test loss to measure the improvement against the prior one\n",
    "    if early_stopping.early_stop:\n",
    "        logger.info(\"Early stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(train_loss= [train_losses],\n",
    "                   val_loss= [test_losses],\n",
    "                   train_acc= [train_metrics],\n",
    "                   val_acc= [test_metrics],\n",
    "                   labels=['advanced_Bert'],\n",
    "                   colors=['green'],\n",
    "                   loss_legend_loc='upper left',\n",
    "                   acc_legend_loc='upper left',\n",
    "                   legend_font=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), \"data/testing/eval_questions.json\")) as file:\n",
    "   eval_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loader = create_data_loader(\n",
    "    question=eval_data[\"questions\"],\n",
    "    targets=eval_data[\"targets\"],\n",
    "    max_len=TokenizerSettings().max_length,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_texts, predictions, prediction_probs, real_values = get_predictions(\n",
    "    bert_base_classifier, eval_loader, device, ModelSettings().binary_thresh\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classific_metrics(real_values, predictions, class_names):\n",
    "    \"\"\"Returns the classification metrics\"\"\"\n",
    "    logger.info(\"Test Accuracy : {}\".format(accuracy_score(real_values, predictions)))\n",
    "    logger.info(f\"Test Recall : {recall_score(real_values, predictions)}\")\n",
    "    logger.info(f\"Test Precision : {precision_score(real_values, predictions)}\")\n",
    "    logger.info(f\"Test F1 Score : {f1_score(real_values, predictions)}\")\n",
    "    logger.info(\"\\nClassification Report : \")\n",
    "    logger.info(classification_report(real_values, predictions, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classific_metrics(real_values, predictions, DataSettings().class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_connection = AzureBlobConnection(\n",
    "    storage_account=env_settings.STORAGE_ACCOUNT,\n",
    "    client_id=env_settings.CLIENT_ID,\n",
    "    tenant_id=env_settings.TENANT_ID,\n",
    "    client_secret=env_settings.SECRET_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Uploading to Azure Blob Storage\")\n",
    "az_connection.azblob_upload(\n",
    "    container_name=env_settings.CONTAINER_NAME,\n",
    "    root_path=os.getcwd(),\n",
    "    local_input_path=AzureblobSettings().input_path,\n",
    "    blob_path=AzureblobSettings().blob_path,\n",
    "    file_names=[]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Downloading from Azure Blob Storage\")\n",
    "az_connection.azblob_download(\n",
    "    container_name=env_settings.CONTAINER_NAME,\n",
    "    root_path=os.getcwd(),\n",
    "    local_output_path=AzureblobSettings().input_path,\n",
    "    blob_path=AzureblobSettings().blob_path,\n",
    "    file_names=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
