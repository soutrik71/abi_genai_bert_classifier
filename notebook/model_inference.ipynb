{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(300000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 300\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\n",
    "    r\"/home/azureuser/cloudfiles/code/Users/soutrik.chowdhury/abi_genai_bert_classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "* donwload the model from azure blob\n",
    "* download the tokenizer from hugging face\n",
    "* pass the incoming data through loader\n",
    "* up the model based on requirements\n",
    "* pass the data through inferencing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/.local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_path\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ('settings_',)`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.settings import (\n",
    "    DataSettings,\n",
    "    env_settings,\n",
    "    ModelSettings,\n",
    "    TokenizerSettings,\n",
    "    AzureblobSettings,\n",
    "    LoggerSettings,\n",
    ")\n",
    "from src.pretrained_model import tokenizer, pretrained_model\n",
    "from src.dataloader import create_data_loader\n",
    "from src.model import BertSentimentClassifier, BertSentimentClassifierAdvanced\n",
    "from src.utils.azure_connector import AzureBlobConnection\n",
    "from src.utils.logger import setup_logging\n",
    "from src.utils.model_helpers import get_device\n",
    "import os, glob\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_connection = AzureBlobConnection(\n",
    "    storage_account=env_settings.STORAGE_ACCOUNT,\n",
    "    client_id=env_settings.CLIENT_ID,\n",
    "    tenant_id=env_settings.TENANT_ID,\n",
    "    client_secret=env_settings.SECRET_ID,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_connection.azblob_download(\n",
    "    container_name=env_settings.CONTAINER_NAME,\n",
    "    root_path=os.getcwd(),\n",
    "    local_output_path=AzureblobSettings().input_path,\n",
    "    blob_path=AzureblobSettings().blob_path,\n",
    "    file_names=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saved_model_path(model_path=AzureblobSettings().input_path):\n",
    "    file_paths = glob.glob(os.path.join(model_path, \"*pt\"))\n",
    "    model_path_dict = {}\n",
    "\n",
    "    for path in file_paths:\n",
    "        if \"advanced\" in path:\n",
    "            model_path_dict[\"advanced\"] = path\n",
    "        elif \"base\" in path:\n",
    "            model_path_dict[\"base\"] = path\n",
    "\n",
    "    return model_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInference:\n",
    "    def __init__(self, tokenizer, model_type, pretrained_model, max_len, prob_thresh):\n",
    "        self.device = get_device()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.prob_thresh = prob_thresh\n",
    "        model_path_dict = saved_model_path()\n",
    "\n",
    "        # model declaration and loading with pretrained weights\n",
    "        if model_type == \"base\":\n",
    "            self.bert_classifier = BertSentimentClassifier(\n",
    "                bert=pretrained_model,\n",
    "                n_classes=ModelSettings().num_classes,\n",
    "                dropout=ModelSettings().drop_out,\n",
    "            )\n",
    "\n",
    "            self.bert_classifier.load_state_dict(\n",
    "                torch.load(f=model_path_dict[\"base\"], map_location=self.device)\n",
    "            )\n",
    "            self.bert_classifier.to(self.device)\n",
    "\n",
    "        elif model_type == \"advanced\":\n",
    "            self.bert_classifier = BertSentimentClassifierAdvanced(\n",
    "                bert=pretrained_model,\n",
    "                n_classes=ModelSettings().num_classes,\n",
    "                dropout=ModelSettings().drop_out,\n",
    "            )\n",
    "            self.bert_classifier.load_state_dict(\n",
    "                torch.load(f=model_path_dict[\"advanced\"], map_location=self.device)\n",
    "            )\n",
    "            self.bert_classifier.to(self.device)\n",
    "\n",
    "    def _get_predictions(self, data_loader, model):\n",
    "        \"\"\"Returns only the predicted labels for the given data loader\"\"\"\n",
    "        review_texts = []\n",
    "        predictions = []\n",
    "        prediction_probs = []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for d in data_loader:\n",
    "                texts = d[\"review_text\"]\n",
    "                input_ids = d[\"input_ids\"].to(self.device)\n",
    "                attention_mask = d[\"attention_mask\"].to(self.device)\n",
    "\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids, attention_mask=attention_mask\n",
    "                ).flatten()\n",
    "\n",
    "                probs = torch.sigmoid(outputs)\n",
    "\n",
    "                preds = torch.where(\n",
    "                    probs > self.prob_thresh,\n",
    "                    torch.tensor(1.0).to(self.device),\n",
    "                    torch.tensor(0.0).to(self.device),\n",
    "                )\n",
    "\n",
    "                review_texts.extend(texts)\n",
    "                predictions.extend(preds)\n",
    "                prediction_probs.extend(probs)\n",
    "\n",
    "        predictions = torch.stack(predictions).cpu().numpy()\n",
    "        prediction_probs = np.round(torch.stack(prediction_probs).cpu().numpy(), 3)\n",
    "\n",
    "        return review_texts, predictions, prediction_probs\n",
    "\n",
    "    def predict(self, user_query):\n",
    "        \"\"\"Returns the predicted labels for the given data loader\"\"\"\n",
    "        query_loader = create_data_loader(\n",
    "            question=[user_query],\n",
    "            targets=None,\n",
    "            max_len=self.max_len,\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            tokenizer=tokenizer,\n",
    "        )\n",
    "        review_texts, predictions, prediction_probs = self._get_predictions(\n",
    "            data_loader=query_loader,\n",
    "            model=self.bert_classifier,\n",
    "        )\n",
    "\n",
    "        return dict(zip(review_texts, zip(list(predictions), list(prediction_probs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_model = ModelInference(\n",
    "    tokenizer=tokenizer,\n",
    "    model_type=ModelSettings().model_type,\n",
    "    pretrained_model=pretrained_model,\n",
    "    max_len=TokenizerSettings().max_length,\n",
    "    prob_thresh=ModelSettings().binary_thresh,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_op = infer_model.predict(\n",
    "    \"What is the notion of people for the new iPhone 13?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'What is the notion of people for the new iPhone 13?': (1.0, 0.937)}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(300000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
